{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b085c213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\Hackaton 2022\\Attempts\\venv\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\User\\Documents\\Hackaton 2022\\Attempts\\venv\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13bb8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_folder, description_csv):\n",
    "        \n",
    "        self.data_folder = data_folder\n",
    "        self.description = pd.read_csv(description_csv)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.description.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.to_list()\n",
    "\n",
    "        images_to_load = list([self.description.iloc[index]['image_name']])\n",
    "        classes = self.description.iloc[index]['class_id']\n",
    "\n",
    "        images = []\n",
    "        for image_relative_path in images_to_load:\n",
    "            images.append(Image.open(os.path.join(self.data_folder, image_relative_path)))\n",
    "        return images, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28bae92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSubset(Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        images, classes = self.subset[index]\n",
    "\n",
    "        result = torch.tensor([])\n",
    "        for image in images:\n",
    "            result = torch.cat([result, self.transform(image)])\n",
    "\n",
    "        return result, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f250b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_epoch, model, criterion, optimizer, train_loader):\n",
    "    iteration = 0\n",
    "    loss_history = []\n",
    "    for epoch in range(n_epoch):\n",
    "        epoch_loss = []\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            model.train()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch.to(device)).cpu()\n",
    "            loss = criterion(logits, y_batch)\n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('+' + '-' * 50)\n",
    "            print(\"| Iteration \", iteration + 1, ', loss: ', epoch_loss[-1], sep='')\n",
    "            print('+' + '-' * 50)\n",
    "            iteration += 1\n",
    "\n",
    "        loss_history.append(np.mean(epoch_loss))\n",
    "        print('/' * 51)\n",
    "        print(\"// EPOCH \", epoch + 1, ', loss: ', loss_history[-1], sep='')\n",
    "        print('/' * 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd26b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    transforms.Resize(400),\n",
    "    transforms.CenterCrop(350),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    transforms.Resize(450),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb7ab78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './data/merged/'\n",
    "MODEL_FOLDER = './models/stacking/'\n",
    "IMAGE_FOLDER = os.path.join(DATA_FOLDER, 'img/')\n",
    "DESCRIPTION_PATH = os.path.join(DATA_FOLDER, 'description.csv')\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "DESCRIPTION = pd.read_csv(DESCRIPTION_PATH)\n",
    "\n",
    "DATASET_SIZE = len(DESCRIPTION)\n",
    "FOLDS_COUNT = 3\n",
    "FOLD_SIZE = DATASET_SIZE // FOLDS_COUNT + 1\n",
    "DATASET = ImageDataset(IMAGE_FOLDER, DESCRIPTION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fea38f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With weapon: 2352, without weapon: 2478\n",
      "Dataset size: 4830\n"
     ]
    }
   ],
   "source": [
    "false_count = np.unique(DESCRIPTION.values[:, 1], return_counts=True)[1][0]\n",
    "true_count = np.unique(DESCRIPTION.values[:, 1], return_counts=True)[1][1]\n",
    "\n",
    "print('With weapon: ', true_count, ', without weapon: ', false_count, sep='')\n",
    "print('Dataset size:', DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3142040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet101(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(ResNet101, self).__init__()\n",
    "        self.model = torchvision.models.resnet101(pretrained=pretrained)\n",
    "        \n",
    "        self.model.fc = nn.Linear(2048, 10)\n",
    "        self.linear = nn.Linear(10, 2)\n",
    "        \n",
    "        layers_count = len(list(self.model.parameters()))\n",
    "        for i, parameter in enumerate(self.model.parameters()):\n",
    "            if i < layers_count - 5:\n",
    "                parameter.requires_grad = False\n",
    "                \n",
    "                \n",
    "    def forward(self, X):\n",
    "        logits = self.model(X)\n",
    "        logits = self.linear(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0706ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet152(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(ResNet152, self).__init__()\n",
    "        self.model = torchvision.models.resnet152(pretrained=pretrained)\n",
    "        \n",
    "        self.model.fc = nn.Linear(2048, 10)\n",
    "        self.linear = nn.Linear(10, 2)\n",
    "        \n",
    "        layers_count = len(list(self.model.parameters()))\n",
    "        for i, parameter in enumerate(self.model.parameters()):\n",
    "            if i < layers_count - 10:\n",
    "                parameter.requires_grad = False\n",
    "                \n",
    "                \n",
    "    def forward(self, X):\n",
    "        logits = self.model(X)\n",
    "        logits = self.linear(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c65e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.model = torchvision.models.densenet201(pretrained=pretrained)\n",
    "        \n",
    "        self.model.classifier = nn.Linear(1920, 10)\n",
    "        self.linear = nn.Linear(10, 2)\n",
    "        \n",
    "        layers_count = len(list(self.model.parameters()))\n",
    "        for i, parameter in enumerate(self.model.parameters()):\n",
    "            if i < layers_count - 5:\n",
    "                parameter.requires_grad = False\n",
    "                \n",
    "                \n",
    "    def forward(self, X):\n",
    "        logits = self.model(X)\n",
    "        logits = self.linear(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c30404",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101_data = pd.read_csv(os.path.join(MODEL_FOLDER, 'resnet101_data.csv'), index_col=0)\n",
    "resnet152_data = pd.read_csv(os.path.join(MODEL_FOLDER, 'resnet152_data.csv'), index_col=0)\n",
    "densenet_data = pd.read_csv(os.path.join(MODEL_FOLDER, 'densenet_data.csv'), index_col=0)\n",
    "\n",
    "data = pd.concat([resnet101_data, resnet152_data, densenet_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959c3b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4830, 10), (4830,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(data.drop(['y'], axis=1))\n",
    "y = np.array(data['y'])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aef50d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3864, 10), (966, 10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97251b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_parameters = {'criterion': ('gini', 'entropy'), 'n_estimators': range(150, 170)}\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "extra = ExtraTreesClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f49874e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8612836438923396\n",
      "0.8581780538302277\n"
     ]
    }
   ],
   "source": [
    "forest.fit(X_train, y_train)\n",
    "extra.fit(X_train, y_train)\n",
    "print(accuracy_score(forest.predict(X_test), y_test))\n",
    "print(accuracy_score(extra.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b143e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(extra, open('extra_tree.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b64475cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "76963c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = CatBoostClassifier(iterations=10, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cbc9868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6451400\ttotal: 21.1ms\tremaining: 190ms\n",
      "1:\tlearn: 0.6035284\ttotal: 23.5ms\tremaining: 94.2ms\n",
      "2:\tlearn: 0.5697062\ttotal: 25.7ms\tremaining: 59.9ms\n",
      "3:\tlearn: 0.5414449\ttotal: 27.9ms\tremaining: 41.8ms\n",
      "4:\tlearn: 0.5153028\ttotal: 30.3ms\tremaining: 30.3ms\n",
      "5:\tlearn: 0.4928609\ttotal: 32.8ms\tremaining: 21.8ms\n",
      "6:\tlearn: 0.4744028\ttotal: 35ms\tremaining: 15ms\n",
      "7:\tlearn: 0.4592100\ttotal: 37ms\tremaining: 9.26ms\n",
      "8:\tlearn: 0.4446717\ttotal: 39.3ms\tremaining: 4.37ms\n",
      "9:\tlearn: 0.4320416\ttotal: 41.5ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1e09c607d60>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a8d0db7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.855072463768116"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(classifier.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6cd994b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60786299, 0.39213701],\n",
       "       [0.76991236, 0.23008764],\n",
       "       [0.23895998, 0.76104002],\n",
       "       ...,\n",
       "       [0.24075949, 0.75924051],\n",
       "       [0.67597783, 0.32402217],\n",
       "       [0.2504208 , 0.7495792 ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "28f080c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save_model('boosting.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c7881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
